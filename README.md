# Toxic-Comments-Classification-Project

Our project focuses on identifying and categorizing toxic comments across various digital platforms into six toxicity levels: toxic, severe toxic, obscene, threat, insult, and identity hate. Utilizing Natural Language Processing (NLP) techniques and machine-learning models, we aim to automate the moderation process to maintain a healthy online community environment. The performance of our models is measured using the F1-score to ensure accuracy and reliability.
